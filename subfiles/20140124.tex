\documentclass[../main.tex]{subfiles}
\begin{document}

\subsection{One-to-All}
\begin{question}
Given are $P$ processors. Processor $p(0)$ sends an element to all processors (one-to-all).
\begin{enumerate}
	\item Given the BSP program.
	\item What is the $h$-relation.
	\item How can this be improved, given that $l << g$.
\end{enumerate}
\end{question}
\begin{solution} The solution to the subquestions are given below.
\begin{enumerate}
	\item The BSP program for one-to-all communication is given below.
\begin{lstlisting}
void oneToAll(){
	bsp_begin(P);
	bsp_push_reg(element);
	for(pid=1; pid<P; pid++){
		bsp_put(pid, data, element, 0, sizeof(data));
	}
	bsp_sync();
	bsp_end();
}
\end{lstlisting}
	\item The $h$-relation is given by $h = max\{h_s,h_r\}$. In the previous case, $p(0)$ sends a single element to
	$(p-1)$ processors.
	\begin{equation}
		h = (p - 1)
	\end{equation}
	The BPS cost is given by $T_\text{comm}(h) = hg + l$, making the cost of this broadcast $(p-1)g + l$.
	\item If the cost of $l$ is significantly less than $g$, splitting the broadcast over multiple communication
	supersteps can reduce cost. Am example is a multi-level broadcast where every processor sends the element to two
	others. In $\log_2(P)$ supersteps, every processor has received the element.
	\begin{equation}
		T_\text{comm} = \lceil \log_2(P) \rceil (2g + l)
	\end{equation}
\end{enumerate}


\end{solution}

\subsection{LU Factorization}
\begin{question}
LU factorization with 2-phase broadcast.
\begin{enumerate}
	\item Give the total sequential cost and its order.
	\item Give the total BSP cost and its order when the data is distributed over $\sqrt{P} \times \sqrt{P}$
	processors.
	\item Given the order of the total cost when distributed over $1 \times P$ processors.
\end{enumerate}
\end{question}
\begin{solution} The solution to the subquestions are given below.
\begin{enumerate}
	\item The number of flops in the LU decomposition with row permutations is given in \autoref{eq:tseqlu}.
	\begin{equation}\label{eq:tseqlu}
		\begin{array}{ll}
		T_{seq} & = \displaystyle\sum_{k=0}^{n-1} (2(n - k - 1)^2 + n - k -1) \\
				& = \displaystyle\sum_{k=0}^{n-1} (2k^2 + k) \\
				& = \dfrac{(n-1)n(2n-1)}{3} + \dfrac{(n-1)n)}{2} \\
				& = \dfrac{2n^3}{3} - \dfrac{n^2}{2} - \dfrac{n}{6} \\
		\end{array}
	\end{equation}
	The sequential LU-decomposition algorithm is $\mathcal{O}(n^3)$.
	\item The number of flops for the parallel LU-decomposition with two-phase broadcast and an \emph{optimal} 2D distribution ($N = \sqrt{P}, M = \sqrt{P}$) is given in \autoref{eq:tparlu}.
	\begin{equation}\label{eq:tparlu}
			T_{LU}  = \dfrac{2n^3}{3p} + \dfrac{3n^2}{2\sqrt{p}} + \dfrac{3n^2g}{\sqrt{p}} + 8nl
	\end{equation}
\item The distribution of processors impacts superstep (1), (3), (6) and (7) as we can find in \cite[p.~70]{bisseling04}. Their new cost is given in \autoref{tbl:lucost}.
	\begin{table}[H]
	\centering
	\begin{tabular}{ll}
		\toprule
		Superstep & Cost  \\
		\midrule
		(1) & $l$ \\
		(3) & $(P-1)g+l$ \\
		(6) & $(C_{k+1} - \lceil C_{k_1}/P  \rceil )g + l$ \\
		(7) & $((P-1) \lceil C_{k+1}/P \rceil )g + l$\\
		\bottomrule
	\end{tabular}
	\caption{New superstep costs.}
	\label{tbl:lucost}
	\end{table}
	Superstep (1) can be removes since no data is sent, making its cost zero. The dominant cost is caused by the matrix update.
	\begin{equation}
		R_{k+1} + C_{k+1} = (n-k-1) \frac{M+N}{p} + 2
	\end{equation}
	For $M = N = \sqrt{P}$, the value is minimal. With the current distribution, this cost is $p (n-k-1) + 2$ or a factor $p$ larger than with the previous one.
\end{enumerate}
\end{solution}

\subsection{Parallel Efficiency}
\begin{question}
Given a multicore program for calculating the average value of a matrix $A$. What is the efficiency and how can we do
better?
\end{question}
\begin{solution} The \emph{Parallel Efficiency} is defined in \autoref{eq:pareff}.
	The efficiency correlates the increase in speedup with the number of processors or can also be seen as the fraction of the total computing power that is usefully employed \cite[p.~141]{bisseling04}.
	The efficiency of a given parallel algorithm can be increased by either decreasing the number of processors (Amdahl's Law) or increasing the problem size $n$.
\begin{equation}\label{eq:pareff}
	E_p(n) = \frac{T_\text{sec}(n)}{p \cdot T_p(n)} = \frac{S_p(n)}{p}
\end{equation}
\end{solution}

\subsection{BSP Quicksort}
\begin{question}
Give a high-level description of a BSP quicksort algorithm. For each step, calculate the BSPC cost ($a + bg + cl$).
Calculate the total cost and give the overhead and efficiency. Discuss your results.
\end{question}
\begin{solution} The algorithm is described below.

\begin{enumerate}
	\item \textbf{Superstep 1:} Determine and broadcast the pivot. This translates to a regular broadcast, with BSP-cost $(p-1)g + l$. Optionally, this can be achieved with a recursion tree, resulting in a cost of $(g+l) \log (p)$.
	\item \textbf{Superstep 2:} Locally rearrange the array assigned to each process. It takes $(n/p)$ FLOPS to compare each value with the pivot. This costs $(n/p) + l$
	\item \textbf{Superstep 3:} Determine the locations in the globally rearranged array that the local elements will go to. This can be achieved by either using \emph{prefix sums} or \emph{partial sums}. Regardless, it translates to all-to-all communication which costs $(p-1)g + l$.
	\item \textbf{Superstep 4:} In this step the the global rearrangement is performed. This is again a case of all-to-all communication, costing $(p-1)g + l$.
\end{enumerate}

The total cost is then the sum of the cost of each superstep. These are repeated $\log(n)$ times.

\begin{equation}
\frac{n \cdot \log(n)}{p} + 3\log(n)(p-1)g + 4\log(n)l
\end{equation}

\end{solution}

\end{document}
